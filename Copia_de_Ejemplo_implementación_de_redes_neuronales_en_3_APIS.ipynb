{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia de Ejemplo_implementación de redes neuronales en 3 APIS.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gomezan/inteligencia-artificial/blob/main/Copia_de_Ejemplo_implementaci%C3%B3n_de_redes_neuronales_en_3_APIS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60MMHVGXO5jp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "outputId": "f12cb864-729f-42ca-c162-8ad8890be842"
      },
      "source": [
        "import numpy as np\n",
        "import scipy as sc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import make_circles\n",
        "\n",
        "# Creamos nuestros datos artificiales, donde buscaremos clasificar \n",
        "# dos anillos concéntricos de datos. \n",
        "X, Y = make_circles(n_samples=500, factor=0.5, noise=0.05)\n",
        "\n",
        "# Resolución del mapa de predicción.\n",
        "res = 100 \n",
        "\n",
        "# Coordendadas del mapa de predicción.\n",
        "_x0 = np.linspace(-1.5, 1.5, res)\n",
        "_x1 = np.linspace(-1.5, 1.5, res)\n",
        "\n",
        "# Input con cada combo de coordenadas del mapa de predicción.\n",
        "_pX = np.array(np.meshgrid(_x0, _x1)).T.reshape(-1, 2)\n",
        "\n",
        "# Objeto vacio a 0.5 del mapa de predicción.\n",
        "_pY = np.zeros((res, res)) + 0.5\n",
        "\n",
        "# Visualización del mapa de predicción.\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.pcolormesh(_x0, _x1, _pY, cmap=\"coolwarm\", vmin=0, vmax=1)\n",
        "\n",
        "# Visualización de la nube de datos.\n",
        "plt.scatter(X[Y == 0,0], X[Y == 0,1], c=\"skyblue\")\n",
        "plt.scatter(X[Y == 1,0], X[Y == 1,1], c=\"salmon\")\n",
        "\n",
        "plt.tick_params(labelbottom=False, labelleft=False)\n",
        "print(Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 0 0 0 1 0 0 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0 1 1 0 1 0 0 1 1 1 0 0 1 1 1\n",
            " 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 1 1 0 1\n",
            " 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 0 0 1 1 1 1 1 1 1 0 0\n",
            " 0 0 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 0 1 0 1 0 0 1 1 0 0 1 1 1 0 1 0 1 1 0 0\n",
            " 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0 1 0 0 0 0 1 1 1 0 0 1 1 1 0\n",
            " 0 0 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0\n",
            " 1 0 0 0 0 1 0 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1\n",
            " 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 1 1 0 1 1 1 1 0 1 0 1 1\n",
            " 1 0 1 1 1 0 1 0 0 0 1 0 1 0 0 1 1 1 0 0 0 1 1 0 0 0 1 1 1 1 0 1 1 1 1 1 1\n",
            " 1 0 0 1 1 0 1 0 0 1 1 0 1 0 1 0 0 0 0 1 0 1 1 1 0 1 1 0 1 1 1 1 0 0 1 0 0\n",
            " 1 0 1 1 1 1 1 1 0 0 1 0 0 0 0 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0 0 0 0 0\n",
            " 0 1 1 1 0 1 1 0 0 1 0 0 1 1 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 1 0 0 0\n",
            " 1 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 1 1 1 1 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1\n",
            " 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 1 1 1 1]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIRqty3YQkJi"
      },
      "source": [
        "SKLearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSRbHOXNPZgC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "618d54ae-be83-46ce-cdfc-c30f45e950bc"
      },
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "lr = 0.01           # learning rate\n",
        "nn = [2, 16, 8, 1]  # número de neuronas por capa.\n",
        "\"\"\"\n",
        "# Creamos el objeto del modelo de red neuronal multicapa.\n",
        "clf = sk.neural_network.MLPRegressor(solver='sgd', \n",
        "                                     learning_rate_init=lr, \n",
        "                                     hidden_layer_sizes=tuple(nn[1:]),\n",
        "                                     verbose=True,\n",
        "                                     n_iter_no_change=1000,\n",
        "                                     batch_size = 64)\n",
        "\n",
        "\n",
        "# Y lo entrenamos con nuestro datos.\n",
        "clf.fit(X, Y)\n",
        "\"\"\"\n",
        "#X, y = make_classification(n_samples=100, random_state=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, stratify=Y,random_state=1)\n",
        "clf = MLPClassifier(random_state=1, max_iter=300,verbose=True).fit(X_train, y_train)\n",
        "clf.predict_proba(X_test[:1])\n",
        "clf.predict(X_test[:5, :])\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 0.70661519\n",
            "Iteration 2, loss = 0.70262194\n",
            "Iteration 3, loss = 0.69884486\n",
            "Iteration 4, loss = 0.69533160\n",
            "Iteration 5, loss = 0.69166674\n",
            "Iteration 6, loss = 0.68889201\n",
            "Iteration 7, loss = 0.68584847\n",
            "Iteration 8, loss = 0.68287821\n",
            "Iteration 9, loss = 0.68006221\n",
            "Iteration 10, loss = 0.67734783\n",
            "Iteration 11, loss = 0.67469530\n",
            "Iteration 12, loss = 0.67203782\n",
            "Iteration 13, loss = 0.66961295\n",
            "Iteration 14, loss = 0.66702349\n",
            "Iteration 15, loss = 0.66455401\n",
            "Iteration 16, loss = 0.66205253\n",
            "Iteration 17, loss = 0.65963615\n",
            "Iteration 18, loss = 0.65715516\n",
            "Iteration 19, loss = 0.65479127\n",
            "Iteration 20, loss = 0.65242199\n",
            "Iteration 21, loss = 0.64996260\n",
            "Iteration 22, loss = 0.64764109\n",
            "Iteration 23, loss = 0.64530568\n",
            "Iteration 24, loss = 0.64303571\n",
            "Iteration 25, loss = 0.64069219\n",
            "Iteration 26, loss = 0.63841012\n",
            "Iteration 27, loss = 0.63613310\n",
            "Iteration 28, loss = 0.63384352\n",
            "Iteration 29, loss = 0.63157216\n",
            "Iteration 30, loss = 0.62928790\n",
            "Iteration 31, loss = 0.62696644\n",
            "Iteration 32, loss = 0.62464053\n",
            "Iteration 33, loss = 0.62227591\n",
            "Iteration 34, loss = 0.61999174\n",
            "Iteration 35, loss = 0.61761128\n",
            "Iteration 36, loss = 0.61532616\n",
            "Iteration 37, loss = 0.61296382\n",
            "Iteration 38, loss = 0.61061564\n",
            "Iteration 39, loss = 0.60832885\n",
            "Iteration 40, loss = 0.60595792\n",
            "Iteration 41, loss = 0.60365861\n",
            "Iteration 42, loss = 0.60131158\n",
            "Iteration 43, loss = 0.59904112\n",
            "Iteration 44, loss = 0.59675689\n",
            "Iteration 45, loss = 0.59446280\n",
            "Iteration 46, loss = 0.59217340\n",
            "Iteration 47, loss = 0.58990686\n",
            "Iteration 48, loss = 0.58761370\n",
            "Iteration 49, loss = 0.58530791\n",
            "Iteration 50, loss = 0.58301948\n",
            "Iteration 51, loss = 0.58071796\n",
            "Iteration 52, loss = 0.57836493\n",
            "Iteration 53, loss = 0.57605412\n",
            "Iteration 54, loss = 0.57377463\n",
            "Iteration 55, loss = 0.57140514\n",
            "Iteration 56, loss = 0.56908600\n",
            "Iteration 57, loss = 0.56681018\n",
            "Iteration 58, loss = 0.56444554\n",
            "Iteration 59, loss = 0.56214372\n",
            "Iteration 60, loss = 0.55976010\n",
            "Iteration 61, loss = 0.55737575\n",
            "Iteration 62, loss = 0.55500030\n",
            "Iteration 63, loss = 0.55259058\n",
            "Iteration 64, loss = 0.55023221\n",
            "Iteration 65, loss = 0.54775529\n",
            "Iteration 66, loss = 0.54535337\n",
            "Iteration 67, loss = 0.54286534\n",
            "Iteration 68, loss = 0.54039215\n",
            "Iteration 69, loss = 0.53794737\n",
            "Iteration 70, loss = 0.53542893\n",
            "Iteration 71, loss = 0.53292064\n",
            "Iteration 72, loss = 0.53043512\n",
            "Iteration 73, loss = 0.52790053\n",
            "Iteration 74, loss = 0.52531981\n",
            "Iteration 75, loss = 0.52281027\n",
            "Iteration 76, loss = 0.52019039\n",
            "Iteration 77, loss = 0.51763423\n",
            "Iteration 78, loss = 0.51504070\n",
            "Iteration 79, loss = 0.51244540\n",
            "Iteration 80, loss = 0.50985900\n",
            "Iteration 81, loss = 0.50732790\n",
            "Iteration 82, loss = 0.50466911\n",
            "Iteration 83, loss = 0.50205773\n",
            "Iteration 84, loss = 0.49950229\n",
            "Iteration 85, loss = 0.49683448\n",
            "Iteration 86, loss = 0.49421805\n",
            "Iteration 87, loss = 0.49162007\n",
            "Iteration 88, loss = 0.48902650\n",
            "Iteration 89, loss = 0.48636938\n",
            "Iteration 90, loss = 0.48375201\n",
            "Iteration 91, loss = 0.48115177\n",
            "Iteration 92, loss = 0.47850740\n",
            "Iteration 93, loss = 0.47583507\n",
            "Iteration 94, loss = 0.47320803\n",
            "Iteration 95, loss = 0.47055169\n",
            "Iteration 96, loss = 0.46786875\n",
            "Iteration 97, loss = 0.46525525\n",
            "Iteration 98, loss = 0.46257695\n",
            "Iteration 99, loss = 0.45995486\n",
            "Iteration 100, loss = 0.45723729\n",
            "Iteration 101, loss = 0.45455662\n",
            "Iteration 102, loss = 0.45189906\n",
            "Iteration 103, loss = 0.44922469\n",
            "Iteration 104, loss = 0.44659258\n",
            "Iteration 105, loss = 0.44388620\n",
            "Iteration 106, loss = 0.44121563\n",
            "Iteration 107, loss = 0.43855405\n",
            "Iteration 108, loss = 0.43586371\n",
            "Iteration 109, loss = 0.43325128\n",
            "Iteration 110, loss = 0.43050422\n",
            "Iteration 111, loss = 0.42783311\n",
            "Iteration 112, loss = 0.42521350\n",
            "Iteration 113, loss = 0.42250575\n",
            "Iteration 114, loss = 0.41982619\n",
            "Iteration 115, loss = 0.41714315\n",
            "Iteration 116, loss = 0.41447252\n",
            "Iteration 117, loss = 0.41182305\n",
            "Iteration 118, loss = 0.40917440\n",
            "Iteration 119, loss = 0.40648828\n",
            "Iteration 120, loss = 0.40382113\n",
            "Iteration 121, loss = 0.40118382\n",
            "Iteration 122, loss = 0.39856594\n",
            "Iteration 123, loss = 0.39587947\n",
            "Iteration 124, loss = 0.39325941\n",
            "Iteration 125, loss = 0.39065592\n",
            "Iteration 126, loss = 0.38801364\n",
            "Iteration 127, loss = 0.38539002\n",
            "Iteration 128, loss = 0.38276267\n",
            "Iteration 129, loss = 0.38023258\n",
            "Iteration 130, loss = 0.37760123\n",
            "Iteration 131, loss = 0.37500694\n",
            "Iteration 132, loss = 0.37240419\n",
            "Iteration 133, loss = 0.36982959\n",
            "Iteration 134, loss = 0.36727243\n",
            "Iteration 135, loss = 0.36472404\n",
            "Iteration 136, loss = 0.36215291\n",
            "Iteration 137, loss = 0.35962568\n",
            "Iteration 138, loss = 0.35710533\n",
            "Iteration 139, loss = 0.35453870\n",
            "Iteration 140, loss = 0.35204679\n",
            "Iteration 141, loss = 0.34953082\n",
            "Iteration 142, loss = 0.34704932\n",
            "Iteration 143, loss = 0.34455814\n",
            "Iteration 144, loss = 0.34212719\n",
            "Iteration 145, loss = 0.33960865\n",
            "Iteration 146, loss = 0.33717352\n",
            "Iteration 147, loss = 0.33469457\n",
            "Iteration 148, loss = 0.33223927\n",
            "Iteration 149, loss = 0.32980986\n",
            "Iteration 150, loss = 0.32739057\n",
            "Iteration 151, loss = 0.32495622\n",
            "Iteration 152, loss = 0.32257366\n",
            "Iteration 153, loss = 0.32015998\n",
            "Iteration 154, loss = 0.31781027\n",
            "Iteration 155, loss = 0.31539378\n",
            "Iteration 156, loss = 0.31307729\n",
            "Iteration 157, loss = 0.31070666\n",
            "Iteration 158, loss = 0.30833510\n",
            "Iteration 159, loss = 0.30599234\n",
            "Iteration 160, loss = 0.30373411\n",
            "Iteration 161, loss = 0.30139417\n",
            "Iteration 162, loss = 0.29911149\n",
            "Iteration 163, loss = 0.29680729\n",
            "Iteration 164, loss = 0.29455319\n",
            "Iteration 165, loss = 0.29230805\n",
            "Iteration 166, loss = 0.29006103\n",
            "Iteration 167, loss = 0.28783502\n",
            "Iteration 168, loss = 0.28562600\n",
            "Iteration 169, loss = 0.28343302\n",
            "Iteration 170, loss = 0.28125470\n",
            "Iteration 171, loss = 0.27908604\n",
            "Iteration 172, loss = 0.27691774\n",
            "Iteration 173, loss = 0.27482074\n",
            "Iteration 174, loss = 0.27262946\n",
            "Iteration 175, loss = 0.27060481\n",
            "Iteration 176, loss = 0.26850250\n",
            "Iteration 177, loss = 0.26634081\n",
            "Iteration 178, loss = 0.26428754\n",
            "Iteration 179, loss = 0.26222867\n",
            "Iteration 180, loss = 0.26022206\n",
            "Iteration 181, loss = 0.25814591\n",
            "Iteration 182, loss = 0.25615939\n",
            "Iteration 183, loss = 0.25418148\n",
            "Iteration 184, loss = 0.25215435\n",
            "Iteration 185, loss = 0.25020841\n",
            "Iteration 186, loss = 0.24822176\n",
            "Iteration 187, loss = 0.24631347\n",
            "Iteration 188, loss = 0.24434521\n",
            "Iteration 189, loss = 0.24244850\n",
            "Iteration 190, loss = 0.24057456\n",
            "Iteration 191, loss = 0.23865448\n",
            "Iteration 192, loss = 0.23679316\n",
            "Iteration 193, loss = 0.23488964\n",
            "Iteration 194, loss = 0.23312512\n",
            "Iteration 195, loss = 0.23123347\n",
            "Iteration 196, loss = 0.22940683\n",
            "Iteration 197, loss = 0.22770397\n",
            "Iteration 198, loss = 0.22584390\n",
            "Iteration 199, loss = 0.22405579\n",
            "Iteration 200, loss = 0.22230360\n",
            "Iteration 201, loss = 0.22053596\n",
            "Iteration 202, loss = 0.21882913\n",
            "Iteration 203, loss = 0.21708549\n",
            "Iteration 204, loss = 0.21541177\n",
            "Iteration 205, loss = 0.21368812\n",
            "Iteration 206, loss = 0.21201999\n",
            "Iteration 207, loss = 0.21034706\n",
            "Iteration 208, loss = 0.20867555\n",
            "Iteration 209, loss = 0.20703554\n",
            "Iteration 210, loss = 0.20541281\n",
            "Iteration 211, loss = 0.20382050\n",
            "Iteration 212, loss = 0.20220398\n",
            "Iteration 213, loss = 0.20060916\n",
            "Iteration 214, loss = 0.19903830\n",
            "Iteration 215, loss = 0.19749311\n",
            "Iteration 216, loss = 0.19592281\n",
            "Iteration 217, loss = 0.19439215\n",
            "Iteration 218, loss = 0.19287154\n",
            "Iteration 219, loss = 0.19134870\n",
            "Iteration 220, loss = 0.18983552\n",
            "Iteration 221, loss = 0.18842928\n",
            "Iteration 222, loss = 0.18689301\n",
            "Iteration 223, loss = 0.18544344\n",
            "Iteration 224, loss = 0.18398140\n",
            "Iteration 225, loss = 0.18256445\n",
            "Iteration 226, loss = 0.18113280\n",
            "Iteration 227, loss = 0.17971571\n",
            "Iteration 228, loss = 0.17831143\n",
            "Iteration 229, loss = 0.17694091\n",
            "Iteration 230, loss = 0.17555267\n",
            "Iteration 231, loss = 0.17418480\n",
            "Iteration 232, loss = 0.17285106\n",
            "Iteration 233, loss = 0.17150301\n",
            "Iteration 234, loss = 0.17017644\n",
            "Iteration 235, loss = 0.16886346\n",
            "Iteration 236, loss = 0.16757931\n",
            "Iteration 237, loss = 0.16626929\n",
            "Iteration 238, loss = 0.16498227\n",
            "Iteration 239, loss = 0.16370221\n",
            "Iteration 240, loss = 0.16244646\n",
            "Iteration 241, loss = 0.16120425\n",
            "Iteration 242, loss = 0.15995947\n",
            "Iteration 243, loss = 0.15880986\n",
            "Iteration 244, loss = 0.15756521\n",
            "Iteration 245, loss = 0.15633521\n",
            "Iteration 246, loss = 0.15515143\n",
            "Iteration 247, loss = 0.15394941\n",
            "Iteration 248, loss = 0.15278834\n",
            "Iteration 249, loss = 0.15162348\n",
            "Iteration 250, loss = 0.15047416\n",
            "Iteration 251, loss = 0.14933973\n",
            "Iteration 252, loss = 0.14820553\n",
            "Iteration 253, loss = 0.14709581\n",
            "Iteration 254, loss = 0.14597811\n",
            "Iteration 255, loss = 0.14486667\n",
            "Iteration 256, loss = 0.14379476\n",
            "Iteration 257, loss = 0.14271587\n",
            "Iteration 258, loss = 0.14163267\n",
            "Iteration 259, loss = 0.14058181\n",
            "Iteration 260, loss = 0.13953422\n",
            "Iteration 261, loss = 0.13849847\n",
            "Iteration 262, loss = 0.13745447\n",
            "Iteration 263, loss = 0.13643363\n",
            "Iteration 264, loss = 0.13542851\n",
            "Iteration 265, loss = 0.13442163\n",
            "Iteration 266, loss = 0.13350481\n",
            "Iteration 267, loss = 0.13244721\n",
            "Iteration 268, loss = 0.13147655\n",
            "Iteration 269, loss = 0.13051084\n",
            "Iteration 270, loss = 0.12964944\n",
            "Iteration 271, loss = 0.12859882\n",
            "Iteration 272, loss = 0.12769517\n",
            "Iteration 273, loss = 0.12675104\n",
            "Iteration 274, loss = 0.12582059\n",
            "Iteration 275, loss = 0.12493042\n",
            "Iteration 276, loss = 0.12400743\n",
            "Iteration 277, loss = 0.12310482\n",
            "Iteration 278, loss = 0.12221207\n",
            "Iteration 279, loss = 0.12132874\n",
            "Iteration 280, loss = 0.12046143\n",
            "Iteration 281, loss = 0.11960797\n",
            "Iteration 282, loss = 0.11875187\n",
            "Iteration 283, loss = 0.11789144\n",
            "Iteration 284, loss = 0.11705630\n",
            "Iteration 285, loss = 0.11623006\n",
            "Iteration 286, loss = 0.11541695\n",
            "Iteration 287, loss = 0.11459213\n",
            "Iteration 288, loss = 0.11378709\n",
            "Iteration 289, loss = 0.11296624\n",
            "Iteration 290, loss = 0.11216851\n",
            "Iteration 291, loss = 0.11148409\n",
            "Iteration 292, loss = 0.11062401\n",
            "Iteration 293, loss = 0.10984466\n",
            "Iteration 294, loss = 0.10907161\n",
            "Iteration 295, loss = 0.10832461\n",
            "Iteration 296, loss = 0.10756895\n",
            "Iteration 297, loss = 0.10681454\n",
            "Iteration 298, loss = 0.10607300\n",
            "Iteration 299, loss = 0.10534665\n",
            "Iteration 300, loss = 0.10462869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75PAshmdQGbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c96830c-9908-415b-c6ee-421d3d68166c"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as kr\n",
        "\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "\n",
        "lr = 0.01           # learning rate\n",
        "nn = [2, 16, 8, 1]  # número de neuronas por capa.\n",
        "\n",
        "\n",
        "# Creamos el objeto que contendrá a nuestra red neuronal, como\n",
        "# secuencia de capas.\n",
        "model = kr.Sequential()\n",
        "\n",
        "# Añadimos la capa 1\n",
        "l1 = model.add(kr.layers.Dense(nn[1], activation='relu'))\n",
        "\n",
        "# Añadimos la capa 2\n",
        "l2 = model.add(kr.layers.Dense(nn[2], activation='relu'))\n",
        "\n",
        "# Añadimos la capa 3\n",
        "l3 = model.add(kr.layers.Dense(nn[3], activation='sigmoid'))\n",
        "\n",
        "# Compilamos el modelo, definiendo la función de coste y el optimizador.\n",
        "model.compile(loss='mse', optimizer=kr.optimizers.SGD(lr=0.05), metrics=['acc'])\n",
        "\n",
        "# Y entrenamos al modelo. Los callbacks \n",
        "model.fit(X, Y, epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 1ms/step - loss: 0.2489 - acc: 0.5160\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2475 - acc: 0.5200\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2462 - acc: 0.5340\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2449 - acc: 0.5320\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2437 - acc: 0.5580\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2426 - acc: 0.5580\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2414 - acc: 0.5860\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2403 - acc: 0.6000\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2391 - acc: 0.6360\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 977us/step - loss: 0.2379 - acc: 0.6660\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2367 - acc: 0.6560\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2354 - acc: 0.7040\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.2342 - acc: 0.7420\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2329 - acc: 0.7300\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.2316 - acc: 0.7540\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.2302 - acc: 0.7460\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2289 - acc: 0.7620\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2275 - acc: 0.7720\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2259 - acc: 0.7820\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2245 - acc: 0.7920\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2229 - acc: 0.8280\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2214 - acc: 0.7900\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2197 - acc: 0.7980\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2180 - acc: 0.8400\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2162 - acc: 0.8240\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2144 - acc: 0.8540\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2125 - acc: 0.8540\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2105 - acc: 0.8640\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.2085 - acc: 0.8640\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2062 - acc: 0.8900\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2039 - acc: 0.8980\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2016 - acc: 0.9020\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1993 - acc: 0.9080\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1969 - acc: 0.9060\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1944 - acc: 0.9220\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1919 - acc: 0.9240\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1894 - acc: 0.9280\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1865 - acc: 0.9360\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1837 - acc: 0.9320\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1809 - acc: 0.9440\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.1778 - acc: 0.9560\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1747 - acc: 0.9540\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1716 - acc: 0.9700\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1683 - acc: 0.9700\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1650 - acc: 0.9800\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1615 - acc: 0.9900\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1581 - acc: 0.9940\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1545 - acc: 0.9940\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1508 - acc: 0.9960\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1471 - acc: 1.0000\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1432 - acc: 1.0000\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1393 - acc: 1.0000\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1351 - acc: 0.9980\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1313 - acc: 1.0000\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1272 - acc: 1.0000\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1231 - acc: 1.0000\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1190 - acc: 1.0000\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1149 - acc: 1.0000\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1109 - acc: 1.0000\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1069 - acc: 1.0000\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1030 - acc: 1.0000\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0991 - acc: 1.0000\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0953 - acc: 1.0000\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0915 - acc: 1.0000\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0879 - acc: 1.0000\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0845 - acc: 1.0000\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0809 - acc: 1.0000\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0776 - acc: 1.0000\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0744 - acc: 1.0000\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0714 - acc: 1.0000\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0684 - acc: 1.0000\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0657 - acc: 1.0000\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0629 - acc: 1.0000\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0604 - acc: 1.0000\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0579 - acc: 1.0000\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0556 - acc: 1.0000\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0535 - acc: 1.0000\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0513 - acc: 1.0000\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0493 - acc: 1.0000\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0473 - acc: 1.0000\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0455 - acc: 1.0000\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0437 - acc: 1.0000\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0421 - acc: 1.0000\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0405 - acc: 1.0000\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0390 - acc: 1.0000\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0376 - acc: 1.0000\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0362 - acc: 1.0000\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0349 - acc: 1.0000\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0337 - acc: 1.0000\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0325 - acc: 1.0000\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0313 - acc: 1.0000\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0303 - acc: 1.0000\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0293 - acc: 1.0000\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0283 - acc: 1.0000\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0274 - acc: 1.0000\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0265 - acc: 1.0000\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0257 - acc: 1.0000\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0248 - acc: 1.0000\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0241 - acc: 1.0000\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0234 - acc: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8bcf976ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Z3Sdpn0V6rJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "5fc21977-5f5c-4669-9f63-290bfdff1a41"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from matplotlib import animation\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "# Definimos los puntos de entrada de la red, para la matriz X e Y.\n",
        "iX = tf.placeholder('float', shape=[None, X.shape[1]])\n",
        "iY = tf.placeholder('float', shape=[None])\n",
        "\n",
        "lr = 0.01           # learning rate\n",
        "nn = [2, 16, 8, 1]  # número de neuronas por capa.\n",
        "\n",
        "# Capa 1\n",
        "W1 = tf.Variable(tf.random_normal([nn[0], nn[1]]), name='Weights_1')\n",
        "b1 = tf.Variable(tf.random_normal([nn[1]]), name='bias_1')\n",
        "\n",
        "l1 = tf.nn.relu(tf.add(tf.matmul(iX, W1), b1))\n",
        "\n",
        "# Capa 2\n",
        "W2 = tf.Variable(tf.random_normal([nn[1], nn[2]]), name='Weights_2')\n",
        "b2 = tf.Variable(tf.random_normal([nn[2]]), name='bias_2')\n",
        "\n",
        "l2 = tf.nn.relu(tf.add(tf.matmul(l1, W2), b2))\n",
        "\n",
        "# Capa 3\n",
        "W3 = tf.Variable(tf.random_normal([nn[2], nn[3]]), name='Weights_3')\n",
        "b3 = tf.Variable(tf.random_normal([nn[3]]), name='bias_3')\n",
        "\n",
        "# Vector de predicciones de Y.\n",
        "pY = tf.nn.sigmoid(tf.add(tf.matmul(l2, W3), b3))[:, 0]\n",
        "\n",
        "\n",
        "# Evaluación de las predicciones.\n",
        "loss = tf.losses.mean_squared_error(pY, iY)\n",
        "\n",
        "# Definimos al optimizador de la red, para que minimice el error.\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.05).minimize(loss)\n",
        "\n",
        "n_steps = 1000 # Número de ciclos de entrenamiento.\n",
        "\n",
        "iPY = [] # Aquí guardaremos la evolución de las predicción, para la animación.\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  \n",
        "  # Inicializamos todos los parámetros de la red, las matrices W y b.\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "    \n",
        "  # Iteramos n pases de entrenamiento.\n",
        "  for step in range(n_steps):\n",
        "  \n",
        "    # Evaluamos al optimizador, a la función de coste y al tensor de salida pY. \n",
        "    # La evaluación del optimizer producirá el entrenamiento de la red.\n",
        "    _, _loss, _pY = sess.run([optimizer, loss, pY], feed_dict={ iX : X, iY : Y })\n",
        "    \n",
        "    # Cada 25 iteraciones, imprimimos métricas.\n",
        "    if step % 25 == 0: \n",
        "      \n",
        "      # Cálculo del accuracy.\n",
        "      acc = np.mean(np.round(_pY) == Y)\n",
        "      \n",
        "      # Impresión de métricas.\n",
        "      print('Step', step, '/', n_steps, '- Loss = ', _loss, '- Acc =', acc)\n",
        "      \n",
        "      # Obtenemos predicciones para cada punto de nuestro mapa de predicción _pX.\n",
        "      _pY = sess.run(pY, feed_dict={ iX : _pX }).reshape((res, res))\n",
        "\n",
        "      # Y lo guardamos para visualizar la animación.\n",
        "      iPY.append(_pY)\n",
        "      \n",
        "  \n",
        "# ----- CÓDIGO ANIMACIÓN ----- #\n",
        "\n",
        "ims = []\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "\n",
        "print(\"--- Generando animación ---\")\n",
        "\n",
        "for fr in range(len(iPY)):\n",
        "  \n",
        "  im = plt.pcolormesh(_x0, _x1, iPY[fr], cmap=\"coolwarm\", animated=True)\n",
        "\n",
        "  # Visualización de la nube de datos.\n",
        "  plt.scatter(X[Y == 0,0], X[Y == 0,1], c=\"skyblue\")\n",
        "  plt.scatter(X[Y == 1,0], X[Y == 1,1], c=\"salmon\")\n",
        "\n",
        "  # plt.title(\"Resultado Clasificación\")\n",
        "  plt.tick_params(labelbottom=False, labelleft=False)\n",
        "\n",
        "  ims.append([im])\n",
        "\n",
        "ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True, repeat_delay=1000)\n",
        "\n",
        "HTML(ani.to_html5_video())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-0611342c2397>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Definimos los puntos de entrada de la red, para la matriz X e Y.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0miX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0miY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XnNIMtwV8_o"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}